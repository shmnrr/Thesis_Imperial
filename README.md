# Papers
## To explore
- <a id="ref-1"></a>[1] [Pion-Tonachini, et al. (2019) ICLabel: An automated electroencephalographic independent component classifier, dataset, and website](https://doi.org/10.1016/j.neuroimage.2019.05.026)
- <a id="ref-2"></a>[2] [Chang, et al. (2012) 'Evaluation of Artifact Subspace Reconstruction for Automatic Artifact Components Removal in Multi-Channel EEG Recordings'](https://ieeexplore.ieee.org/abstract/document/6280801/metrics)
- <a id="ref-3"></a>[3] [Blum, et al. (2019) A Riemannian Modification of Artifact Subspace Reconstruction for EEG Artifact Handling](https://www.frontiersin.org/articles/10.3389/fnhum.2019.00141/full#B145)
- <a id="ref-4"></a>[4] [Otero, et al. (2020) Persistence of EEG Alpha Entrainment Depends on Stimulus Phase at Offset](https://doi.org/10.3389/fnhum.2020.00139)
- <a id="ref-5"></a>[5] [Scherg, et al. (2019) Taking the EEG back into the brain: The power of multiple discrete sources](https://doi.org/10.3389/FNEUR.2019.00855)
- <a id="ref-6"></a>[6] [BrainMasterTechnologies (2022) BA 10-20 ROI Talairach](http://www.brainm.com/software/pubs/dg/BA_10-20_ROI_Talairach/nearest.eeg.htm)
- <a id="ref-7"></a>[7] [MikeXCohen, Massachusetts Institute of Technology MIT press (2014) Analyzing Neural Time Series Data: Theory and Practice]()
- <a id="ref-8"></a>[8] [Lenz, et al. (2011) Joint EEG/fMRI state space model for the detection of directed interactions in human brains—a simulation study](https://doi.org/10.1088/0967-3334/32/11/S01)
- <a id="ref-9"></a>[9] [Ives-Deliperi & Butler (2018) Relationship Between EEG Electrode and Functional Cortex in the International 10 to 20 System](https://doi.org/10.1097/WNP.0000000000000510)
- <a id="ref-10"></a>[10] [Delorme & Makeig (2004) EEGLAB: an open-source toolbox for analysis of single-trial EEG dynamics](https://doi.org/10.1016/j.jneumeth.2003.10.009)
- <a id="ref-11"></a>[11] [Abiri, et al. (2019) Multi-Modal Haptic Feedback for Grip Force Reduction in Robotic Surgery](https://doi.org/10.1038/s41598-019-40821-1)
- <a id="ref-12"></a>[12] [Moore, et al. (2021) Grasping Embodiment: Haptic Feedback for Artificial Limbs](https://www.frontiersin.org/articles/10.3389/fnbot.2021.662397/full)
- <a id="ref-13"></a>[13] [Turolla, et al. (2013) Haptic-based neurorehabilitation in poststroke patients: a feasibility prospective multicentre trial for robotics hand rehabilitation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3844272/)
- <a id="ref-14"></a>[14] [Melendez-Calderon, et al. (2011) Hi5: A versatile dual-wrist device to study human-human interaction and bimanual control](https://doi.org/10.1109/IROS.2011.6094422)
- <a id="ref-15"></a>[15] [Ganesh, et al. (2014) Two is better than one: Physical interactions improve motor performance in humans](https://doi.org/10.1038/srep03824)
- <a id="ref-16"></a>[16] [Takagi, et al. (2017) Physically interacting individuals estimate the partner's goal to enhance their movements](https://doi.org/10.1038/s41562-017-0054)
- <a id="ref-17"></a>[17] [Ivanova, et al. (2020) For Motion Assistance Humans Prefer to Rely on a Robot Rather Than on an Unpredictable Human](https://doi.org/10.1109/OJEMB.2020.2987885)
- <a id="ref-18"></a>[18] [Chauvigné, et al. (2018) Taking two to tango: fMRI analysis of improvised joint action with physical contact](https://doi.org/10.1371/JOURNAL.PONE.0191098)
- <a id="ref-19"></a>[19] [Dumas, et al. (2020) The Human Dynamic Clamp Reveals the Fronto-Parietal Network Linking Real-Time Social Coordination and Cognition](https://doi.org/10.1093/CERCOR/BHZ308)
- <a id="ref-20"></a>[20] [Liu, et al. (2018) Interactive brain activity: Review and progress on EEG-based hyperscanning in social interactions](https://doi.org/10.3389/FPSYG.2018.01862)
- <a id="ref-21"></a>[21] [Zhou, et al. (2016) Neural signatures of hand kinematics in leaders vs. followers: A dual-MEG study](https://doi.org/10.1016/J.NEUROIMAGE.2015.11.002)
- <a id="ref-22"></a>[22] [Limanowski, et al. (2020) Action-Dependent Processing of Touch in the Human Parietal Operculum and Posterior Insula](https://doi.org/10.1093/CERCOR/BHZ111)

## Brain Networks
- <a id="ref-23"></a>[23] [Yu et al. (2022) EEG-based emotion recognition in an immersive virtual reality environment: From local activity to brain network features](https://www.sciencedirect.com/science/article/pii/S1746809421009460?casa_token=FbznPMAAo-kAAAAA:AMR01UyhXvcNaLPTqc0m_HD5DQWMpHvDNGUEututWwkP9aksmglTOdrO8THhpuFuFIU1ez5t)

## Esports
- <a id="ref-24"></a>[24] [Minami, et al. (2024) Prediction of esports competition outcomes using EEG data from expert players](https://www.sciencedirect.com/science/article/pii/S074756322400219X)
- <a id="ref-25"></a>[25] [Minami et al. (2023) Neural oscillation amplitude in the frontal cortex predicts esport results](https://www.cell.com/iscience/fulltext/S2589-0042(23)00922-7)
- <a id="ref-26"></a>[26] [Ramyarangsi, et al. (2024) EEG differences in competitive female gymnastics, soccer, and esports athletes between resting states with eyes closed and open](https://www.nature.com/articles/s41598-024-74665-1)
- <a id="ref-27"></a>[27] [Ramyarangsi, et al. (2024)  Distinct Visual Processing Patterns in Female Elite Athletes: A Comparative Study of Gymnastics, Soccer, and Esports Using Visual P300 Event-Related Potentials](https://pmc.ncbi.nlm.nih.gov/articles/PMC11728593/)
- <a id="ref-28"></a>[28] [Using EEG and Gamified Neurofeedback Environments to Improve eSports Performance: Project Neuroprotrainer](https://www.scitepress.org/PublishedPapers/2021/103145/103145.pdf)
- <a id="ref-29"></a>[29] [Gaze and Electroencephalography (EEG) Parameters in Esports: Examinations Considering Genres and Skill Levels](https://www.researchgate.net/publication/373555248_Gaze_and_Electroencephalography_EEG_Parameters_in_Esports_Examinations_Considering_Genres_and_Skill_Levels)
- <a id="ref-30"></a>[30] [The Research of Applying Affective Computing Based on Deep Learning for eSports Training](https://link.springer.com/chapter/10.1007/978-981-15-3250-4_15)
- <a id="ref-31"></a>[31] [eSports Players Professional Level and Tiredness Prediction using EEG and Machine Learning](https://ieeexplore.ieee.org/abstract/document/9278704)
- <a id="ref-32"></a>[32] [Biomarkers of professional cybersportsmen: Event related potentials and cognitive tests study](https://pmc.ncbi.nlm.nih.gov/articles/PMC10393144/)
- <a id="ref-33"></a>[33] [Tosti et al. 2024 Neurofeedback Training Protocols in Sports: A Systematic Review of Recent Advances in Performance, Anxiety, and Emotional Regulation](https://www.mdpi.com/2076-3425/14/10/1036)
- <a id="ref-34"></a>[34] [Smerdov et al. (2020) Collection and Validation of Psychophysiological Data from Professional and Amateur Players: a Multimodal eSports Dataset](https://paperswithcode.com/paper/collection-and-validation-of)
- <a id="ref-35"></a>[35] [Liu & Juan (2025) Leveraging deep learning for robust EEG analysis in mental health monitoring](https://www.frontiersin.org/journals/neuroinformatics/articles/10.3389/fninf.2024.1494970/full)
- <a id="ref-36"></a>[36] [Ahmed et al. (2024) Recent Trends in EEG-Based P300, Neuromarketing, and E-Sports Brain-Computer Interface Applications](https://www.researchgate.net/publication/386065326_Recent_Trends_in_EEG-Based_P300_Neuromarketing_and_E-Sports_Brain-Computer_Interface_Applications)
- <a id="ref-37"></a>[37] [Patino et al. (2025) Integration Between Serious Games and EEG Signals: A Systematic Review](https://www.mdpi.com/2076-3417/15/4/1946)
- <a id="ref-38"></a>[38] [Doma (2025) EEG as an input for virtual reality](https://link.springer.com/content/pdf/10.1007/978-3-031-23161-2_176.pdf)
- <a id="ref-39"></a>[39] [Lachowicz et al. (2024) Amplifying Cognitive Functions in Amateur Esports Athletes: The Impact of Short-Term Virtual Reality Training on Reaction Time, Motor Time, and Eye–Hand Coordination](https://www.mdpi.com/2076-3425/14/11/1104)
- [Berga et al. (2024) The Stress Is Real: Physiological Measurement of League of Legends
Players Experience During a Live Esports Event](https://www.scitepress.org/Papers/2024/129817/129817.pdf)
- [Solder Dominguez, Gonzalez (2021) Using EEG and Gamified Neurofeedback Environments to Improve
eSports Performance: Project Neuroprotrainer](https://www.scitepress.org/PublishedPapers/2021/103145/103145.pdf)
- <a id="ref-40"></a>[40] [Rodrigues-Vion et al. (2023) Training, lifestyle and physiological conditions and performance in esports](https://sportrxiv.org/index.php/server/preprint/view/278)
- <a id="ref-41"></a>[41] [Melentev et al. (2020) eSports Players Professional Level and Tiredness Prediction using EEG and Machine Learning](https://www.researchgate.net/publication/347548303_eSports_Players_Professional_Level_and_Tiredness_Prediction_using_EEG_and_Machine_Learning)
- <a id="ref-42"></a>[42] [Beres et al. (2023) Playing with Emotions: A Systematic Review Examining Emotions and Emotion Regulation in Esports Performance](https://dl.acm.org/doi/abs/10.1145/3611041)
- <a id="ref-43"></a>[43] [Chiossi et al. (2025) Designing and Evaluating an Adaptive Virtual Reality System using EEG Frequencies to Balance Internal and External Attention States](https://www.sciencedirect.com/science/article/pii/S1071581924002167)

## BCI
- <a id="ref-44"></a>[44] [Chen et al., (2024) A method for dynamically adjusting the difficulty of rehabilitation training tasks driven by attention level](https://iopscience.iop.org/article/10.1088/1741-2552/ada0e9)
- <a id="ref-45"></a>[45] [Atilla et al., (2024) Gamification of motor imagery brain-computer interface training protocols: A systematic review](https://www.sciencedirect.com/science/article/pii/S2451958824001416)
- <a id="ref-46"></a>[46] [Vavoulis et al. (2023) A Review of Online Classification Performance in Motor Imagery-Based Brain–Computer Interfaces for Stroke Neurorehabilitation](https://www.mdpi.com/2624-6120/4/1/4)
- <a id="ref-47"></a>[47] [Taghazideh, Chalechale (2024) Motor Imagery Classification Using <b>Single Channel</b> of EEG in Online Brain-Computer Interface](https://ieeexplore.ieee.org/abstract/document/10533373)<br>The achieved
results indicate high accuracy for left and right-hand
movement, with 100% accuracy for left-hand movement and
87.47% accuracy for right-hand movement. These results were
accomplished using SVM with the RBF kernel and KNN
algorithms, based on power features extracted from the eighth-level EEG signal;
up to 35 Hz for MI
- <a id="ref-48"></a>[48] [Ge et al. (2014) Classification of Four-Class Motor Imagery Employing Single-Channel Electroencephalography](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0098019)<br>CSP requires multiple channels -> Short-Time Fourier Transform (STFT). Examined Fp1, Fpz, Fp2, C3, Cz and C4. C4 - highest accuracy of 88.1%. "Accuracies obtained using C3, Cz and C4, which are over the sensorimotor area, were equivalent to those obtained using Fp1, Fpz and Fp2, which are far from the motor cortex", "We would like to
significantly increase the task complexity to ensure a wider range of
performance based on a user’s cognitive capacity. This would enable
a range of interesting experiments, such as being able to predict the
user’s performance based on the cognitive capacity measured with
the N-back task at the beginning of the experiment"
- <a id="ref-49"></a>[49] [Mladenovic et al., (2018) Towards Identifying Optimal Biased Feedback for Various User States and Traits in Motor Imagery BCI](https://ieeexplore.ieee.org/abstract/document/9541030)
- <a id="ref-50"></a>[50] [Dhillon et al., (2021) A Raspberry Pi-Based Traumatic Brain Injury Detection System for Single-Channel Electroencephalogram](https://pmc.ncbi.nlm.nih.gov/articles/PMC8071098/)
- <a id="ref-51"></a>[51] [Benomar et al., (2022) Investigation of EEG-Based Biometric Identification Using State-of-the-Art Neural Architectures on a Real-Time Raspberry Pi-Based System](https://www.mdpi.com/1424-8220/22/23/9547)

### DL
- <a id="ref-52"></a>[52] [Nguyen et al., (2024) EEG-TCNTransformer: A Temporal Convolutional Transformer for Motor Imagery Brain–Computer Interfaces](https://www.mdpi.com/2624-6120/5/3/34)
- <a id="ref-53"></a>[53] [Taghizadeh et al., (2024) EEG Motor Imagery Classification by Feature Extracted Deep 1D-CNN and Semi-Deep Fine-Tuning](https://ieeexplore.ieee.org/abstract/document/10601693)<br>code @ https://github.com/MohamadTaghizadeh/EEG-1DCNN; exceptional performance with transfer learning enabling versatile applications - have to inspect the time to train, cause although might be "low" in the DL sense, it might turn out not applicable in this project; "success of the SCSP method suggests that employing all channels or generating a global CSP may not be the best approach for EEG. The locally generated common spatial pattern (LRCSP) method, detailed in [23], improves performance by forming local regions through the grouping of adjacent channels starting from several central channels"

## Neurofeedback
- <a id="ref-54"></a>[54] [Jao et al., (2022) EEG Correlates of Difficulty Levels in Dynamical Transitions of Simulated Flying and Mapping Tasks](https://ieeexplore.ieee.org/abstract/document/9284594)<br>"EEG correlates of the task difficulty level do not instantaneously reflect the changes (...) latency, could be as high as ten seconds"; attention - correlated witha parietal alpha C4ish and frontal theta 
- <a id="ref-55"></a>[55] [Dey et al, (2021) Exploration of an EEG-Based Cognitively Adaptive Training System in Virtual Reality](https://ieeexplore.ieee.org/abstract/document/8797840)<br>"adaptive VR training can be developed with the potential to increase the user’s cognitive load without affecting task performance"; " as the difficulty level increased, so did alpha activity, with no significant difference in response time"
- <a id="ref-56"></a>[56] [Bagarinao 2018 Improved Volitional Recall of Motor-Imagery-Related Brain Activation Patterns Using Real-Time Functional MRI-Based Neurofeedback](https://pmc.ncbi.nlm.nih.gov/articles/PMC5928248/)

## PiEEG
- <a id="ref-57"></a>[57] [Mosa, M. M. M., & Harris, A. R. A. (2024). Home Automation for Disabled Using Brain Computer Interface and Raspberry Pi. HumEnTech](https://doi.org/10.11113/humentech.v3n2.77)
- <a id="ref-58"></a>[58] [Rincon, J.A., Julian, V., Carrascosa, C. (2022). A Physical Cognitive Assistant for Monitoring Hand Gestures Exercises.](https://link.springer.com/chapter/10.1007/978-3-031-06527-9_2)
- <a id="ref-59"></a>[59] [N. Patel, J. Verma and S. Jain. (2023). Emerging Applications of Brain-Computer Interfaces: A Comprehensive Review and Future Perspectives.](https://www.researchgate.net/publication/379096844_Emerging_Applications_of_Brain_Computer_Interfaces_A_Comprehensive_Review_and_Future_Perspectives)
- <a id="ref-60"></a>[60] [Zohny H, Savulescu J. (2024). When Two Become One: Singular Duos and the Neuroethical Frontiers of Brain-to-Brain Interfaces.](https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/article/when-two-become-one-singular-duos-and-the-neuroethical-frontiers-of-braintobrain-interfaces/4416F124088FF38A262A5BD62F55750A)
- <a id="ref-61"></a>[61] [I. Rakhmatuiln, M. Zhanikeev and A. Parfenov. (2021). Raspberry PI Shield – for measuring EEG (PIEEG). 2021 5th International Conference on Electrical, Electronics, Communication, Computer Technologies and Optimization Techniques](https://ieeexplore.ieee.org/document/9707969)
- <a id="ref-62"></a>[62] [Rakhmatulin, I., Parfenov, A., Traylor, Z. et al. (2021). Low-cost brain-computer interface for everyday use.](https://link.springer.com/article/10.1007/s00221-021-06231-4#citeas)
- <a id="ref-63"></a>[63] [Rakhmatulin, I. (2022).  Brain-Computer-Interface controlled robot via RaspberryPi and PiEEG](https://arxiv.org/abs/2202.01936)
- <a id="ref-64"></a>[64] [Rakhmatulin, I. (2024). PiEEG-16 to Measure 16 EEG Channels with Raspberry Pi for Brain-Computer Interfaces and EEG devices](https://doi.org/10.48550/arXiv.2409.07491)
- <a id="ref-65"></a>[65] [Rakhmatulin, I. (2024). JNEEG shield for Jetson Nano for real-time EEG signal processing with deep learning.](https://arxiv.org/abs/2405.09575)

# Websites
### Brain
- <a id="ref-66"></a>[66] [Large-scale networks](https://en.wikipedia.org/wiki/Large-scale_brain_network)

### Toolkits
- <a id="ref-67"></a>[67] [LORETA EEG](https://peakbraininstitute.com/how-to-use-loreta-eeg-source-localization-to-understand-qeeg/)
- <a id="ref-68"></a>[68] [BrainMasterTechnologies (2022) BA 10-20 ROI Talairach](http://www.brainm.com/software/pubs/dg/BA_10-20_ROI_Talairach/nearest.eeg.htm)
- <a id="ref-69"></a>[69] [EEGLAB Study Statistics and Visualization Options](https://eeglab.org/tutorials/10_Group_analysis/study_stati)
- <a id="ref-70"></a>[70] [EEGLAB Time/frequency decomposition](https://eeglab.org/tutorials/08_Plot_data/Time-Frequency_decomposition.html)
- <a id="ref-71"></a>[71] [EEGLAB Independent Component Analysis for artifact removal](https://eeglab.org/tutorials/06_RejectArtifacts/RunICA.html)
- <a id="ref-72"></a>[72] [MNE](https://mne.tools/stable/auto_tutorials/inverse/index.html)

### E-sports
- <a id="ref-73"></a>[73] [eAthlete Labs](https://eathletelabs.com)

### EEG devices & tutorials
- <a id="ref-74"></a>[74] [g.tec medical engineering GmbH Austria. (2022) g.NAUTILUS RESEARCH WEARABLE EEG HEADSET](https://www.gtec.at/product/gnautilus-research/)
- <a id="ref-75"></a>[75] [Mindgarden kit](https://mindgardenai.com/blog/2024-09-11-lets-build-a-bci/)
- <a id="ref-76"></a>[76] [Mingarden Wi-fi Connection](https://mindgardenai.com/blog/2024-09-27-building-an-advanced-real-time-eeg-analysis-app-with-python-and-brainflow/)

### General EEG
- <a id="ref-77"></a>[77] [10-20](https://www.tmsi.artinis.com/blog/the-10-20-system-for-eeg)

# Videos
- <a id="ref-78"></a>[78] [Galea](https://www.youtube.com/watch?v=uhLxggasiqE)
- <a id="ref-79"></a>[79] [Quest 2 - Raspberry pi connection](https://www.youtube.com/watch?v=oBgdrZi8WAk)

# Repos
- <a id="ref-80"></a>[80] [EEG Lab](https://github.com/sccn/eeglab)
- <a id="ref-81"></a>[81] [Arnaud Delorme, Salk Institute (2001) pop_runica](https://github.com/sccn/eeglab/blob/develop/functions/p)
- <a id="ref-82"></a>[82] [Mark IV](https://github.com/OpenBCI/Ultracortex/tree/master/Mark_IV/MarkIV-FINAL/STL_Directory)

# Notes
## Brain waves [i](https://nhahealth.com/brainwaves-the-language/), [45](#ref-45)
- delta (<4 Hz)
- theta (4-8 Hz, ~20 µV) 
- alpha (8-13 Hz, 30-50 µV)
- beta (13-30 Hz, 5-30 µV)
- gamma (>30 Hz)

Measurement range 0.5-100 µV

![Brain Wave Graphs](resources/reference_graphs/brain_waves.jpg)

## Motor Function [45](#ref-45)
